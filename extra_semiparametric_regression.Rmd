---
title: "Bayesian Analysis final project"
author: "Adam Olivares"
date: "2025-05-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# FISH example (Duke admission exam)

```{r}
library(nimble)
library(ggplot2)
library(tidyverse)

fish_df <- read.table("mercury-bass_0.txt", header = T)

fish_df <- fish_df %>% mutate(RIVER = as.factor(RIVER))
```

Data exploration

```{r}
p_dual <- ggplot(tibble(fish_df)) +
  geom_histogram(aes(x=MERCURY)) +
  facet_wrap(~ RIVER) 
p_dual
ggsave("fish_mercury_plot_histogram.pdf", p_dual, width = 10, height = 5)
```

```{r}
library(cowplot)

p1<-ggplot(fish_df) +
aes(x = WEIGHT, y = MERCURY, color= RIVER) +
  geom_point() 

p2 <- ggplot(fish_df) +
aes(x = LENGTH, y = MERCURY, color= RIVER) +
  geom_point() 

combined_plot <- plot_grid(p1, p2, ncol = 2)
plot_grid(p1, p2, ncol = 2)
ggsave("fish_mercury_plot.pdf", combined_plot, width = 10, height = 5)
```

Effects look linear, but random slopes seems to be needed

```{r}
p_facet_weight <- ggplot(fish_df) +
aes(x = WEIGHT, y = log(MERCURY), color= RIVER) +
  geom_point() +
facet_wrap(~ RIVER + STATION) 

p_facet_weight
ggsave("fish_mercury_plot_facet_weight.pdf", p_facet_weight, width = 10, height = 5)
```

```{r}
p_facet_length <- ggplot(fish_df) +
aes(x = LENGTH, y = log(MERCURY), color= RIVER) +
  geom_point() +
facet_wrap(~ RIVER + STATION)

p_facet_length
ggsave("fish_mercury_plot_facet_length.pdf", p_facet_length, width = 10, height = 5)
```

```{r}
library(cowplot)

p1<-ggplot(fish_df) +
aes(x = WEIGHT, y = log(MERCURY), color= RIVER) +
  geom_point() 

p2 <- ggplot(fish_df) +
aes(x = LENGTH, y = log(MERCURY), color= RIVER) +
  geom_point() 

plot_grid(p1, p2, ncol = 2)
ggsave("fish_log_mercury_plot.pdf", combined_plot, width = 10, height = 5)
```


## Nimble code (Hierarchical regression)

### CRP CONSTRUCTION

```{r}
# Define the number of clusters
K <- length(unique(fish_df$STATION))  # Maximum possible number

codeBNP <- nimbleCode({
  # Gaussian Regression
  for (i in 1:N) {
    mercury[i] ~ dnorm(mu_reg[i], sd = sigma)
    mu_reg[i] <- beta0 + beta1 * river[i] + beta2 * length[i] + beta3 * weight[i] + b[station[i]]
  }
  # Station random effects via DPM (b_j)
  for (m in 1:M) {
    b[m] ~ dnorm(muTilde[ki[m]], sd = sqrt(sigma2Tilde[ki[m]]))
  }
  # CRP for clustering stations (maximum as many clusters as station)
  ki[1:M] ~ dCRP(alpha, size = M)
  ## Mixture component parameters
  for (k in 1:K) {
    muTilde[k] ~ dnorm(mu0, var = var0)
    sigma2Tilde[k] ~ dinvgamma(a0, b0)
  }
  # Hyperpriors for DPM (CRP construction)
  alpha ~ dgamma(4, 1)
  #mu0 ~ dnorm(0, var = 10)
  #var0 ~ dinvgamma(2, 1)
  #a0 ~ dinvgamma(2, 1)
  #b0 ~ dinvgamma(2, 1)
  
  ## Regression hyperparameters
  beta0 ~ dnorm(0, var = 25)
  beta1 ~ dnorm(0, var = 25)
  beta2 ~ dnorm(0, var = 25)
  beta3 ~ dnorm(0, var = 25)
  # Residual standard deviation
  sigma ~ dinvgamma(2, 1)

})

# Pack data in the format needed for compilation 
fish_df$STATION <- as.numeric(factor(fish_df$STATION))
fish_constants <- list(
  N = nrow(fish_df),
  M = length(unique(fish_df$STATION)),
  K = K,
  station = fish_df$STATION,
  #hyperparams,
  mu0 = 0,
  var0 = 1,
  a0 = 2,
  b0 = 1
)

fish_data <- list(
  mercury = log(fish_df$MERCURY),
  length = fish_df$LENGTH,
  river = as.numeric(fish_df$RIVER),
  weight = fish_df$WEIGHT
)

#List with some initial values
inits <- list(
  beta0 = 0, beta1 = 0, beta2 = 0, beta3 =0,
  b = rep(0, fish_constants$M),
  #sigma =  rep(1, fish_constants$N),
  sigma = 1,
  alpha = 1,
  #mu0 = 0,
  #var0 = 1,
  #a0 = 2,
  #b0 = 2,
  muTilde = rnorm(K, 0, 5),
  sigma2Tilde = 1/rgamma(K, shape = 2, rate = 1), # inv gamama
  ki = sample(c(1:10), fish_constants$M, replace = TRUE)
)

```


### STICK-BREAKING CONSTRUCTION [Sethuraman, J. (1994)]

```{r}
# Define the number of clusters
M <- length(unique(fish_df$STATION))  # Maximum possible number (NOT TRUNCATED)

codeBNP <- nimbleCode({
  # Gaussian Regression
  for (i in 1:N) {
    mercury[i] ~ dnorm(mu_reg[i], var = sigma[i])
    mu_reg[i] <- beta0 + beta1 * river[i] + beta2 * length[i] + beta3 * weight[i] + b[station[i]]
  }
  # Station random effects via DPM (b_j)
  for (m in 1:M) {
    b[m] ~ dnorm(muTilde[ki[m]], var = sigma2Tilde[ki[m]])
  }
  # Stick-Breaking process
  for(i in 1:(M-1)) { # stick-breaking variables
      v[i] ~ dbeta(1, alpha)
    }
    w[1:M] <- stick_breaking(v[1:(M-1)]) # stick-breaking weights
  ## Mixture component parameters
  for (m in 1:M) {
    ki[m] ~ dcat(w[1:M]) #sample categories based on weights for clustering stations (maximum as many clusters as station)
    muTilde[m] ~ dnorm(mu0, var = var0)
    sigma2Tilde[m] ~ dinvgamma(a0, b0)
  }
  # Hyperpriors for DPM (Stick-Breaking construction)
  alpha ~ dgamma(4, 1)
  #mu0 ~ dnorm(0, var = 10)
  #var0 ~ dinvgamma(2, 2)
  #a0 ~ dinvgamma(2, 2)
  #b0 ~ dinvgamma(2, 2)
  
  ## Regression hyperparameters
  beta0 ~ dnorm(0, var = 10)
  beta1 ~ dnorm(0, var = 10)
  beta2 ~ dnorm(0, var = 10)
  beta3 ~ dnorm(0, var = 10)
  # Residual standard deviation
  for(i in 1:N){
  sigma[i] ~ dinvgamma(2, 2)
  }
  #sigma ~ dinvgamma(2, 2)

})

# Pack data in the format needed for compilation 
fish_df$STATION <- as.numeric(factor(fish_df$STATION))
fish_constants <- list(
  N = nrow(fish_df),
  M = length(unique(fish_df$STATION)),
  station = fish_df$STATION,
  #hyperparams,
  mu0 = 0,
  var0 = 5,
  a0 = 2,
  b0 = 1
)

fish_data <- list(
  mercury = log(fish_df$MERCURY),
  length = fish_df$LENGTH,
  river = as.numeric(fish_df$RIVER),
  weight = fish_df$WEIGHT
)

#List with some initial values
inits <- list(
  beta0 = 0, beta1 = 0, beta2 = 0, beta3 =0,
  b = rep(0, fish_constants$M),
  sigma =  rep(1, fish_constants$N),
  #sigma = 1,
  alpha = 1,
  v = rbeta(fish_constants$M-1, 1, 1),
  #mu0 = 0,
  #var0 = 1,
  #a0 = 2,
  #b0 = 2,
  muTilde = rnorm(M, 0, 5),
  sigma2Tilde = 1/rgamma(M, shape = 2, rate = 1), # inv gamama
  ki = sample(c(1:10), fish_constants$M, replace = TRUE)
)

```

<!-- 

```{r}
# Define the number of clusters
M <- length(unique(fish_df$STATION))  # Maximum possible number (NOT TRUNCATED)

codeBNP <- nimbleCode({
  # Gaussian Regression
  for (i in 1:N) {
    mercury[i] ~ dnorm(mu_reg[i], var = sigma[i])
    mu_reg[i] <- beta0 + beta1 * river[i] + beta2 * length[i] + beta3 * weight[i] + b[station[i]]
  }
  # Station random effects via DPM (b_j)
  for (m in 1:M) {
    b[m] ~ dnorm(muTilde, var = sigma2Tilde)
  }
  ## Regression hyperparameters
  beta0 ~ dnorm(0, var = 25)
  beta1 ~ dnorm(0, var = 25)
  beta2 ~ dnorm(0, var = 25)
  beta3 ~ dnorm(0, var = 25)
  muTilde ~ dnorm(mu0, var = var0)
  sigma2Tilde ~ dinvgamma(a0, b0)
  # Residual standard deviation
  for(i in 1:N){
  sigma[i] ~ dinvgamma(2, 1)
  }

})

# Pack data in the format needed for compilation 
fish_df$STATION <- as.numeric(factor(fish_df$STATION))
fish_constants <- list(
  N = nrow(fish_df),
  M = length(unique(fish_df$STATION)),
  station = fish_df$STATION
)

fish_data <- list(
  mercury = log(fish_df$MERCURY),
  length = fish_df$LENGTH,
  river = as.numeric(fish_df$RIVER),
  weight = fish_df$WEIGHT
)

#List with some initial values
inits <- list(
  beta0 = 0, beta1 = 0, beta2 = 0, beta3 =0,
  b = rep(0, fish_constants$M),
  sigma =  rep(1, fish_constants$N),
  #sigma = 1,
  mu0 = 0,
  var0 = 1,
  a0 = 2,
  b0 = 1,
  muTilde = rnorm(1, 0, 5),
  sigma2Tilde = 1/rgamma(1, shape = 2, rate = 1) # inv gamama
)

```

--->

```{r}
set.seed(1234)
#MCMC
model <- nimbleModel(code = codeBNP, inits = inits, data = fish_data,
                          constants = fish_constants)

## Ensure we have the nodes needed to simulate new datasets
dataNodes <- model$getNodeNames(dataOnly = TRUE)
parentNodes <- model$getParents(dataNodes, stochOnly = TRUE)  # `getParents` is new in nimble 0.11.0
## Ensure we have both data nodes and deterministic intermediates (e.g., lifted nodes)
simNodes <- model$getDependencies(parentNodes, self = FALSE)

cmodel <- compileNimble(model)
mcmc    <- buildMCMC(model, monitors = c(parentNodes, "muTilde", "sigma2Tilde", "ki"))
cmcmc <- compileNimble(mcmc, project = model)
samplesBNP <- runMCMC(cmcmc, niter = 1100000, nburnin = 600000, nchains = 3, thin = 20)
```


```{r}
library(MCMCvis) #same stan output format
MCMCsummary(object = samplesBNP, round = 5)
```

```{r}
pdf("MCMCbeta_estimate.pdf", width = 8, height = 8)  
par(mfrow = c(2, 2))
MCMCplot(object =samplesBNP, params = c("beta0"))
MCMCplot(object =samplesBNP, params = c("beta1"))
MCMCplot(object =samplesBNP, params = c("beta2"))
MCMCplot(object =samplesBNP, params = c("beta3"))
dev.off()
```

```{r}
pdf("MCMCb_estimate.pdf", width = 8, height = 8)  
MCMCplot(object =samplesBNP, params = "b")
dev.off()
```

```{r}
pdf("MCMC_cluster_params_estimate.pdf", width = 8, height = 8)  
par(mfrow = c(1, 2))
MCMCplot(object =samplesBNP, params = c("muTilde"))
MCMCplot(object =samplesBNP, params = c("sigma2Tilde"))
dev.off()
```


```{r}
MCMCtrace(object = samplesBNP, pdf =F, ind=T, params = c("beta1", "beta2","beta3"))
```

```{r}
MCMCtrace(object = samplesBNP, pdf =F, ind=T, params = "ki")
```


Posterior predictive


```{r}
nSamp <- nrow(samplesBNP)
n <- length(fish_df$MERCURY)
ppSamples <- matrix(0, nSamp, n)
ppSamples <- matrix(0, nrow = nSamp, ncol =
          length(model$expandNodeNames(dataNodes, returnScalarComponents = TRUE)))
postNames <- colnames(samplesBNP)

set.seed(1)
system.time({
for(i in seq_len(nSamp)) {
    values(cmodel, postNames) <- samplesBNP[i, ]  # assign 'flattened' values
    cmodel$simulate(simNodes, includeData = TRUE)
    ppSamples[i, ] <- values(cmodel, dataNodes)
}
})
```

```{r}
ppSamplerNF <- nimbleFunction(
          setup = function(model, mcmc) {
              dataNodes <- model$getNodeNames(dataOnly = TRUE)
              parentNodes <- model$getParents(dataNodes, stochOnly = TRUE)
              cat("Stochastic parents of data are:", paste(parentNodes, collapse = ','), ".\n")
              simNodes <- model$getDependencies(parentNodes, self = FALSE)
              vars <- mcmc$mvSamples$getVarNames()  # need ordering of variables in mvSamples / samples matrix
              cat("Using posterior samples of:", paste(vars, collapse = ','), ".\n")
              n <- length(model$expandNodeNames(dataNodes, returnScalarComponents = TRUE))
          },
          run = function(samples = double(2)) {
              nSamp <- dim(samples)[1]
              ppSamples <- matrix(nrow = nSamp, ncol = n)   
              for(i in 1:nSamp) {
                    values(model, vars) <<- samples[i, ]
                    model$simulate(simNodes, includeData = TRUE)
                    ppSamples[i, ] <- values(model, dataNodes)
              }
              returnType(double(2))       
              return(ppSamples)
          })
```


```{r}
## Create the sampler for this model and this MCMC.
ppSampler <- ppSamplerNF(model, mcmc)
cppSampler <- compileNimble(ppSampler, project = model)
colnames(samplesBNP)  
```

```{r}
obsMean <- mean(log(fish_df$MERCURY))
ppMean <- apply(ppSamples, 1, mean)

# plot it!
hist(ppMean,
    main = "Discrepancy = mean(y)", 
    xlab = "mean(y_rep)")
abline(v = obsMean, col = 'red')
```

CHECK PARAMETER POSTERIORS AND CHAINS

```{r}
# You can now compute posterior predictive means, intervals, etc.
#pp_means <- apply(ppSamples, 2, mean)
#pp_CI <- rowMeans(apply(ppSamples, 2, quantile, probs = c(0.025, 0.975)))

pp_samples <- as.vector(ppSamples)
pp_CI <- rowMeans(apply(ppSamples, 2, quantile, probs = c(0.025, 0.975)))

# plot it!
hist(pp_samples,
    main = "Samples from y_post", 
    xlab = "y_post")
abline(v = pp_CI, col = 'red')
```


```{r}
bCols <- grep('^b\\[', colnames(samplesBNP[[1]]))
bMn <- colMeans(samplesBNP[[1]][ , bCols])
kiCols <- grep('ki', colnames(samplesBNP[[1]]))

par(mfrow = c(1,3), cex = 1.1, mgp = c(1.8,.7,0))
hist(bMn, xlab = 'posterior means',
              main = "random effects distrib'n")
hist(samplesBNP[[1]][1000, bCols], xlab = 'single draw',
                   main = "random effects distrib'n")

# How many mixture components are inferred?
xiRes <- samplesBNP[[1]][ , kiCols]
nGrps <- apply(xiRes, 1, function(x) length(unique(x)))
ts.plot(nGrps, xlab = 'iteration', ylab = 'number of components',
   main = 'number of components')
```

```{r}
#Total number of clusters sampled in simulation t
sort(table(nGrps),decreasing=TRUE)[1:max(unique(nGrps))]
```

```{r}
pdf("b_posterior_overall.pdf", width = 8, height = 8)  

bMn <- as.vector(samplesBNP[[1]][ , bCols])
hist(bMn, xlab = 'b_j',
              main = "random effects distribution")
dev.off()
```


```{r}
pdf("k_distributions_post.pdf", width = 8, height = 8)  
par(mfrow = c(1,2))
xiRes <- samplesBNP[[1]][ , kiCols]
nGrps <- apply(xiRes, 1, function(x) length(unique(x)))
ts.plot(nGrps, xlab = 'iteration', ylab = 'Number of components k',
   main = 'number of components')


ki_all <- as.vector(xiRes)
hist(ki_all, xlab = 'k', xlim=c(1,16),
              main = "k distribution (posterior draws)")
dev.off()
```


## Frequentist approach

```{r}
#fish_df <- fish_df %>%
#  mutate(LENGTH = as.vector(scale(LENGTH)), 
#         WEIGHT = as.vector(scale(WEIGHT)))
```


```{r}
library(lme4)
library(lmerTest)

frequentist_mod <- lmer(log(MERCURY) ~ RIVER + LENGTH + WEIGHT + (1|STATION) , data =fish_df)
summary(frequentist_mod)
```

```{r}
cond_res_lme = residuals(frequentist_mod)
plot(x = predict(frequentist_mod), y = cond_res_lme)
```

```{r}
par(mfrow = c(1,2))
hist(cond_res_lme)
qqnorm(cond_res_lme)
qqline(cond_res_lme)
```

Residuals look normally distributed overall.

The estimated random effects (the BLUPs) should be approximately normal. Let's see if that's true.

```{r}
reff = nlme::ranef(frequentist_mod)
qqnorm(reff$STATION[,1])
qqline(reff$STATION[,1])
```